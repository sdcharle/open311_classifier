{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open311 Classifier\n",
    "Find within some exploration of the Open311DataSet and some classification experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92286 entries, 0 to 92285\n",
      "Data columns (total 13 columns):\n",
      "service_request_id    92286 non-null int64\n",
      "requested_datetime    92286 non-null object\n",
      "updated_datetime      92286 non-null object\n",
      "closed_date           92286 non-null object\n",
      "status                92286 non-null object\n",
      "source                58419 non-null object\n",
      "service_name          92286 non-null object\n",
      "service_subtype       0 non-null float64\n",
      "description           84009 non-null object\n",
      "agency_responsible    24915 non-null object\n",
      "address               86808 non-null object\n",
      "lat                   74468 non-null float64\n",
      "long                  74470 non-null float64\n",
      "dtypes: float64(3), int64(1), object(9)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# how about nltk though?\n",
    "\n",
    "DATA_FOLDER = './data/'\n",
    "reports = pd.read_csv(os.path.join(DATA_FOLDER, 'Open311Data.csv'))\n",
    "reports.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of particular interest is the 'description' column. No doubt location, date, and time info could prove useful. First we just use text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trash                                 40124\n",
       "Recycling                             18606\n",
       "Excessive Growth                       7445\n",
       "Yard Waste                             4586\n",
       "Other                                  2556\n",
       "Potholes, Other Street Repair          2020\n",
       "Temporary Signage w/o permit           1730\n",
       "Sewer Problems (Sanitary Sewers)       1467\n",
       "Water Utility Problems                 1358\n",
       "Sidewalk Snow Removal                  1297\n",
       "Parking on Unimproved Surface          1009\n",
       "Street Lights                           922\n",
       "Graffiti                                749\n",
       "Water Quality                           730\n",
       "Traffic Related Complaints              654\n",
       "Street Snow Removal                     635\n",
       "Line of Sight                           572\n",
       "Blocked Street                          558\n",
       "Traffic Signals                         503\n",
       "Website & Mobile Apps Feedback          451\n",
       "Sidewalk & Curb Complaints              444\n",
       "Parks & Playgrounds                     396\n",
       "Unsafe Buildings                        320\n",
       "Sewer Problems (Storm Sewers)           319\n",
       "Traffic Suggestions                     314\n",
       "Biking & Walking                        248\n",
       "Water Utility Billing Problems          228\n",
       "Trails                                  216\n",
       "City Performance                        211\n",
       "Animal Control                          202\n",
       "Blocked sidewalk                        190\n",
       "Drainage or Runoff                      164\n",
       "Parking Meters and Tickets              154\n",
       "Abandoned Vehicle                       134\n",
       "Public Works Projects                   115\n",
       "Sidewalk Requests                       110\n",
       "Sand Removal                             87\n",
       "Fire Hazards                             69\n",
       "Parking Permits                          61\n",
       "Business                                 50\n",
       "Parks & Rec Programs                     49\n",
       "Leaf Collection                          42\n",
       "Utilities Construction                   38\n",
       "Inaccessible Parking                     33\n",
       "Parks & Rec Buildings                    32\n",
       "Bus Services (Bloomington Transit)       28\n",
       "Utilities Yardwork                       23\n",
       "Open311 API Key Request                  17\n",
       "Accessibility Problem                    10\n",
       "Smoking Violation                         4\n",
       "Taxi Complaints                           3\n",
       "Crow Sightings                            3\n",
       "Name: service_name, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports['service_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download() # kicks off a GUI thing\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh snap. lots of NaN descriptions. That's no help!\n",
    "Do your data massaging here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreports = reports[(pd.notnull(reports['description']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = goodreports['service_name'] == 'Trash'\n",
    "#y = goodreports['service_name'] == 'Recycling'\n",
    "#y = goodreports['service_name'] == 'Excessive Growth'\n",
    "#y = goodreports['service_name'] == 'Yard Waste'\n",
    "#y = goodreports['service_name'] == 'Potholes, Other Street Repair'\n",
    "#y = goodreports['service_name'] == 'Temporary Signage w/o permit'\n",
    "#y = goodreports['service_name'] == 'Sewer Problems (Sanitary Sewers)'\n",
    "#y = goodreports['service_name'] == 'Water Utility Problems'\n",
    "#y = goodreports['service_name'] == 'Sidewalk Snow Removal'\n",
    "#y = goodreports['service_name'] == 'Parking on Unimproved Surface'\n",
    "#y = goodreports['service_name'] == 'Graffiti'\n",
    "x = goodreports['description']\n",
    "\n",
    "# do da splits 33 for test? 25 is better?\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8806766944414385"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM time\n",
    "# changing num_iter=5 to max_iter=5 made it go wild son\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                                   alpha=1e-3, max_iter=5, random_state=42)),\n",
    "                         ])\n",
    "\n",
    "_ = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "np.mean(predicted_svm == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717671247700466"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "text_clf_nb = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB()),\n",
    "                         ])\n",
    "\n",
    "_ = text_clf_nb.fit(X_train, y_train)\n",
    "predicted_nb = text_clf_nb.predict(X_test)\n",
    "np.mean(predicted_nb == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be a not too bad idea to look at where/how it failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20134                     Bags must have sticker attached.\n",
       "24553                       10/24/07\\r\\ncan exceeds 35 gal\n",
       "66568                                            too heavy\n",
       "4941       Trash piled behind duplex and blowing in alley.\n",
       "41568                             Missed pick-up/recycling\n",
       "27321                          had tv in trash for pick up\n",
       "34295    Missed pick-up/ This is the second week she ha...\n",
       "22617                                          no stickers\n",
       "37462                                 no stickers on trash\n",
       "39480                                         S-no sticker\n",
       "44155                    TYR##OF##\\nREQUEST FOR FLAG STOP.\n",
       "10802    Bags/cans must have sticker attached.  Boxes n...\n",
       "37057                                           no sticker\n",
       "36820                                           no sticker\n",
       "46528    Resident has been written up many times in 201...\n",
       "17060                                    Courtesy Pick up.\n",
       "66979                                  ###B###\\n2nd notice\n",
       "25704                                          no stickers\n",
       "27414                                            o/w trash\n",
       "30118          Exceeds weight limit of 40 lbs.  Too heavy.\n",
       "28000                 Exceeds can limit of 35 gallons. 954\n",
       "38663    Other/trash:  Trash can of Christmas paper.  T...\n",
       "25886                               can exceeds size limit\n",
       "15873                                    over weight limit\n",
       "24420                                   can exceeds 35 gal\n",
       "19484                        Exceeds 40 pound weight limit\n",
       "30999    Missed pick-up/trash:  Took recycling - has \"n...\n",
       "25996                               can exceeds size limit\n",
       "12149    Habitually not stickering their trash.  A lett...\n",
       "13548                     Bags must have sticker attached.\n",
       "                               ...                        \n",
       "15794                                           NO STICKER\n",
       "30721                               $2 per can or bag. 954\n",
       "44382    Resident has been written up numerous times in...\n",
       "38798                           Th-A/Missed pick-up/trash:\n",
       "19965                     Bags must have sticker attached.\n",
       "27787                     Bags must have sticker attached.\n",
       "49222               trash between 616 and 622 n Washington\n",
       "29828           Bags must have sticker attached.  $2 tags.\n",
       "20505                                       exceeds 35 gal\n",
       "48091                           all kinds of trash in yard\n",
       "44401    Exceeds can limit of 35 gallons; unacceptable ...\n",
       "19511                                accumulation of trash\n",
       "29470    Exceeds weight limit of 40 lbs, exceeds can li...\n",
       "10869    Bags cans must have sticker attached\\r\\n\\r\\n\\r...\n",
       "12798         scattered trash, trash bags, beer cans, etc.\n",
       "44085    ##RM#####\\nSays everyone on park between 1st a...\n",
       "33584                     BAGS MUST HAVE STICKER ATTACHED.\n",
       "30250    Exceeds weight limit of 40 lbs, bags must have...\n",
       "18433    Exceeds can limit of 35 gallons. Unacceptable ...\n",
       "34201            faxed Ddh/ Missed pick-up/trash/recycling\n",
       "39776                                 Missed pick-up/trash\n",
       "23819                                   can exceeds 35 gal\n",
       "37813    Other/trash:  She missed her Wed. pick-up and ...\n",
       "26819                               can exceeds size limit\n",
       "29552    Bags must have sticker attached.  Trash must b...\n",
       "10795                Bags/cans must have sticker attached.\n",
       "15081                                           no sticker\n",
       "18418    has been notified to end Monster trash removal...\n",
       "13338    There has been trash/recycling sitting out by ...\n",
       "41299    Other/Recycling:  You left half of her recycli...\n",
       "Name: description, Length: 11098, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrong predictions...very few (sewer deal)\n",
    "X_test[predicted_nb]\n",
    "# it's what we seek\n",
    "#X_test[predicted_nb == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_svm.predict(['sticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    15548\n",
       "True     12175\n",
       "Name: service_name, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8683757524312836,\n",
       " 0.8717671247700466,\n",
       " 0.8745249960366767,\n",
       " 0.8650427106835875)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test[y_test]\n",
    "#X_test[predicted_nb]\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "fmeasure1 = f1_score(y_test, predicted_nb, average=\"macro\")\n",
    "fmeasure2 = f1_score(y_test, predicted_nb, average=\"micro\")\n",
    "\n",
    "precision = precision_score(y_test, predicted_nb, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_nb, average=\"macro\")\n",
    "\n",
    "fmeasure1,fmeasure2,precision,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers below are Naive Bayes\n",
    "\n",
    "So in the example of the sewer, it says '99%' correct prediction, but out of 476 it only picks up 247 (low sensitivity) - so it's sort of like the accuracy of a fraud detection alg. that always says 'there's no fraud'\n",
    "\n",
    "For recycling:\n",
    "flagged 3754 while there are 5131\n",
    "\n",
    "Growth\n",
    "947 flagged, 2190 in fact. Hmmm :(\n",
    "\n",
    "Next things:\n",
    "confusion matrices\n",
    "'balance' the data?\n",
    "\n",
    "For graffiti, precision, recall\n",
    "\n",
    "0.9406737870149864,\n",
    " 0.5184150018713973\n",
    " \n",
    "NEXT:\n",
    "Tree methods\n",
    "Logistic Regression\n",
    "Is label encoding legit?\n",
    "What would the russian kids do?\n",
    "\n",
    "The multiclass thing doesn't look good at all really\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/metrics/ranking.py:571: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC Curve\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predicted_nb, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 6]\n",
      "[0 0 1 2]\n",
      "[1 1 2 6]\n",
      "['bobs' 'burgers' 'funny' 'is']\n",
      "[0 0 2]\n",
      "['bobs' 'bobs' 'funny']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([1, 2, 2, 6])\n",
    "print(le.classes_)\n",
    "print(le.transform([1, 1, 2, 6])) \n",
    "print(le.inverse_transform([0, 0, 1, 2]))\n",
    "le.fit(['bobs','burgers','is','funny'])\n",
    "print(le.classes_)\n",
    "print(le.transform(['bobs', 'bobs', 'funny'])) \n",
    "print(le.inverse_transform([0, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Recycling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0             Excessive Growth\n",
       "1             Excessive Growth\n",
       "2             Excessive Growth\n",
       "3             Excessive Growth\n",
       "4             Excessive Growth\n",
       "5             Excessive Growth\n",
       "11            Excessive Growth\n",
       "13            Excessive Growth\n",
       "14            Excessive Growth\n",
       "15            Excessive Growth\n",
       "16            Excessive Growth\n",
       "17            Excessive Growth\n",
       "18            Excessive Growth\n",
       "20            Excessive Growth\n",
       "21            Excessive Growth\n",
       "22            Excessive Growth\n",
       "23            Excessive Growth\n",
       "24            Excessive Growth\n",
       "25            Excessive Growth\n",
       "26            Excessive Growth\n",
       "27            Excessive Growth\n",
       "28            Excessive Growth\n",
       "29            Excessive Growth\n",
       "30            Excessive Growth\n",
       "31            Excessive Growth\n",
       "32            Excessive Growth\n",
       "33            Excessive Growth\n",
       "34            Excessive Growth\n",
       "35            Excessive Growth\n",
       "36            Excessive Growth\n",
       "                 ...          \n",
       "92256         Blocked sidewalk\n",
       "92257         Blocked sidewalk\n",
       "92258         Blocked sidewalk\n",
       "92259         Blocked sidewalk\n",
       "92260         Blocked sidewalk\n",
       "92261         Blocked sidewalk\n",
       "92262         Blocked sidewalk\n",
       "92263         Blocked sidewalk\n",
       "92264         Blocked sidewalk\n",
       "92265         Blocked sidewalk\n",
       "92266         Blocked sidewalk\n",
       "92267         Blocked sidewalk\n",
       "92268         Blocked sidewalk\n",
       "92269         Blocked sidewalk\n",
       "92270         Blocked sidewalk\n",
       "92271         Blocked sidewalk\n",
       "92272        Smoking Violation\n",
       "92273        Smoking Violation\n",
       "92274        Smoking Violation\n",
       "92275        Smoking Violation\n",
       "92276    Accessibility Problem\n",
       "92277    Accessibility Problem\n",
       "92278    Accessibility Problem\n",
       "92279    Accessibility Problem\n",
       "92280    Accessibility Problem\n",
       "92281    Accessibility Problem\n",
       "92282    Accessibility Problem\n",
       "92283    Accessibility Problem\n",
       "92284    Accessibility Problem\n",
       "92285    Accessibility Problem\n",
       "Name: service_name, Length: 84009, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#le.fit(goodreports['service_name'].unique())\n",
    "#y_vect = le.transform(goodreports['service_name'])\n",
    "#print(y_vect)\n",
    "#print(np.max(y_vect))\n",
    "# I do not believe this worked!\n",
    "#y = label_binarize(y_vect, classes=le.classes_) # [0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ,10])\n",
    "# can just jump straight to binarizer, but....\n",
    "yz = lb.fit_transform(goodreports['service_name'])\n",
    "print(yz[84000])\n",
    "#lb.fit_transform(['eat',' a shit','and','die'])\n",
    "print(goodreports['service_name'][84000])\n",
    "goodreports['service_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84009\n",
      "84009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 1 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 3 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 4 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 5 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 6 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 7 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 8 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 9 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 10 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 11 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 12 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 13 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 14 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 15 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 16 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 18 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 19 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 20 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 21 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 22 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 23 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 25 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 26 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 27 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 28 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 29 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 31 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 32 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 33 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 34 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 35 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 36 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 37 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 38 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 39 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 40 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 41 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 42 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 43 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 44 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 45 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 46 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 47 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 48 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 49 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 50 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Users/scharlesworth/.pyenv/versions/3.6.3/envs/open-311-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 51 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this one is highly dubious!\n",
    "from sklearn import svm\n",
    "print(len(y))\n",
    "x=goodreports['description']\n",
    "print(len(x))\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "# Learn to predict each class against the other\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "text_clf_svc = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=7))),\n",
    "                         ])\n",
    "\n",
    "_ = text_clf_svc.fit(X_train, y_train)\n",
    "predicted_svc = text_clf_svc.predict(X_test)\n",
    "np.mean(predicted_svc == y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9009948386136113, 0.9030047253183278, 0.9038392505524209, 0.898976993284095)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "fmeasure1 = f1_score(y_test, predicted_svc, average=\"macro\")\n",
    "fmeasure2 = f1_score(y_test, predicted_svc, average=\"micro\")\n",
    "\n",
    "precision = precision_score(y_test, predicted_svc, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_svc, average=\"macro\")\n",
    "\n",
    "fmeasure1,fmeasure2,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ..., False,  True, False])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75850    False\n",
       "28960     True\n",
       "4906     False\n",
       "75999    False\n",
       "56174    False\n",
       "30516     True\n",
       "385      False\n",
       "24331     True\n",
       "9534     False\n",
       "10430     True\n",
       "14703     True\n",
       "52986    False\n",
       "75053    False\n",
       "50268    False\n",
       "60089    False\n",
       "24406     True\n",
       "20460     True\n",
       "59632    False\n",
       "7057     False\n",
       "24608     True\n",
       "44145     True\n",
       "43586     True\n",
       "9883     False\n",
       "42826     True\n",
       "30588     True\n",
       "19602     True\n",
       "62014    False\n",
       "24077     True\n",
       "16301     True\n",
       "65148    False\n",
       "         ...  \n",
       "72764    False\n",
       "36772     True\n",
       "71053    False\n",
       "63641    False\n",
       "2793     False\n",
       "19377     True\n",
       "26613     True\n",
       "77266    False\n",
       "29669     True\n",
       "58025    False\n",
       "91374    False\n",
       "5556     False\n",
       "73298    False\n",
       "70250    False\n",
       "68248    False\n",
       "64241    False\n",
       "803      False\n",
       "70145    False\n",
       "72550    False\n",
       "42099     True\n",
       "16957     True\n",
       "64773    False\n",
       "46382     True\n",
       "38194     True\n",
       "90654    False\n",
       "6893     False\n",
       "59222    False\n",
       "83317    False\n",
       "894      False\n",
       "16725     True\n",
       "Name: service_name, Length: 56286, dtype: bool"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-311-env",
   "language": "python",
   "name": "open-311-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
